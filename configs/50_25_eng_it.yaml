l1_dataset_path: data/tokenized/50_25_eng_it/l1_train
l2_dataset_path: data/tokenized/50_25_eng_it/l2_train
output_dir: output/50_25_eng_it
tokenizer_path: tokenizer/50_25_eng_it
architectures_path: configs/model_architectures.yaml
train_from_scratch: true
model_arch_type: gpt2
model_size_tag: gpt2-100m
num_train_epochs: 1
per_device_train_batch_size: 8
gradient_accumulation_steps: 16
learning_rate: 0.0005
weight_decay: 0.01
max_grad_norm: 1.0
lr_scheduler_type: linear
num_warmup_steps: 100
use_amp: true
num_workers: 4
seed: 42
logging_steps: 100
save_steps: 500
checkpoint_schedule:
- 1
- 2
- 4
- 8
- 16
- 20
- 32
- 40
- 60
- 64
- 79
- 99
- 119
- 128
- 139
- 158
- 178
- 198
- 218
- 237
- 256
- 257
- 277
- 296
- 316
- 336
- 356
- 375
- 395
- 415
- 435
- 454
- 474
- 494
- 512
- 513
- 533
- 553
- 573
- 592
- 612
- 632
- 652
- 671
- 691
- 711
- 730
- 750
- 770
- 790
- 809
- 829
- 849
- 869
- 888
- 908
- 928
- 947
- 967
- 987
- 1007
- 1026
- 1046
- 1066
- 1086
- 1105
- 1125
- 1145
- 1164
- 1184
- 1204
- 1224
- 1243
- 1263
- 1283
- 1303
- 1322
- 1342
- 1362
- 1381
- 1401
- 1421
- 1441
- 1460
- 1480
- 1500
- 1520
- 1539
- 1559
- 1579
- 1598
- 1618
- 1638
- 1658
- 1677
- 1697
- 1717
- 1737
- 1756
- 1776
- 1796
- 1815
- 1835
- 1855
- 1875
- 1894
- 1914
- 1934
- 1954
- 1955
- 1956
- 1958
- 1962
- 1970
- 1974
- 1986
- 1994
- 2014
- 2018
- 2034
- 2054
- 2074
- 2082
- 2094
- 2114
- 2134
- 2154
- 2174
- 2194
- 2210
- 2213
- 2233
- 2253
- 2273
- 2293
- 2313
- 2333
- 2353
- 2373
- 2393
- 2413
- 2433
- 2452
- 2472
- 2492
- 2512
- 2532
- 2552
- 2572
- 2592
- 2612
- 2632
- 2652
- 2672
- 2691
- 2711
- 2731
- 2751
- 2771
- 2791
- 2811
- 2831
- 2851
- 2871
- 2891
- 2911
- 2931
